{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEE 690, Lecture 19 Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This course will make use of notebook style coding.  Notebooks are incredibly useful tools both for teaching and for disseminating data anlysis.\n",
    "\n",
    "This is a set of codes to revisist penalized regression, statistical testing, and false discovery rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:\n",
    "\n",
    "This section provides some initialization commands, which can simply be copied for assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# We need to import key libraries that we're going to use.  \n",
    "# For now this is just numpy, which is our linear algebra library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the random seed for code reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs, we are going to see the random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have to reset the random seed _every_ time we run an algorithm if we want the same results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to set up a plotting environment and make it look pretty.  For those of you familiar with matlab, we will be using matplotlib which is fairly close in syntax and feel.  It's not too far off from R either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# This command figures show up in the notebook.  It's a \"magic\" command...\n",
    "# Typically, this now happens by default so it is often an unnecessary command, but is good for standardization.\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These commands will help us save figures; not going to go through them so much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "PROJECT_SAVE_DIR = \"18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes the directory if it doesn't exist.\n",
    "import os\n",
    "if not (os.path.isdir(PROJECT_ROOT_DIR+'/'+PROJECT_SAVE_DIR)):\n",
    "    print('Figure directory didn\\'t exist, creating now.')\n",
    "    os.mkdir(PROJECT_ROOT_DIR+'/'+PROJECT_SAVE_DIR)\n",
    "else:\n",
    "    print('Figure directory exists.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple defined helper function.\n",
    "def savepdf(fig,name):\n",
    "    fig.savefig(PROJECT_ROOT_DIR+'/'+PROJECT_SAVE_DIR+'/'+name+'.pdf',transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./data/AQ_Mortality/train.csv')\n",
    "# show the first 5 rows\n",
    "data=data.dropna()\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dataset that gives air quality measurements (ozone, pm 10, pm 2.5, nitric oxide) and temperature in kelvins and gives the accompanying mortality rate (as measured through the national health system in England) on that data. This dataset contains multiple regions, so we're going to limit ourself to a single region to make this a standard time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions=np.unique(data['region'].values)\n",
    "single_region_data=data[data.region==regions[0]]\n",
    "single_region_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using a data frame, we're going to use a standard matrix here.  We'll do this by converting to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortality_rates=single_region_data.mortality_rate.values.astype('float64')\n",
    "covariates=single_region_data.values[:,4:].astype('float64')\n",
    "dates=single_region_data.date.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the format of the dates..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what does $y$ (our mortality rates) look like as a time series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(mortality_rates)\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Mortality Rate')\n",
    "plt.show()\n",
    "savepdf(fig,'full_series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see the trends better by showing in years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(np.arange(0,1/365*len(mortality_rates),1/365),mortality_rates)\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Mortality Rate')\n",
    "plt.show()\n",
    "savepdf(fig,'full_series_years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First we just set up the problem _without_ cross-validation to see the forecasting setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we predict from recent history?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's vary over the number of 'lags' in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lag=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we take the measurements from the day before to predict the current values.  We're going to start by only predicting the current morality rates from only the older mortality rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our new 'X' matrix\n",
    "n_max=len(mortality_rates)\n",
    "X=np.zeros([n_max-n_lag,n_lag])\n",
    "for i in range(0,n_max-1):\n",
    "    X[i]=mortality_rates[i:i+n_lag]\n",
    "y=mortality_rates[n_lag:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model to see how well this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg=linear_model.LinearRegression()\n",
    "lin_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built in $R^2$ coefficient, which gives us the amount of explained variance. Note that this is _training_ $R^2$, so be cautious with this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we explain 14% of the variance, which isn't so bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does adding more history give us a better forecasting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg=linear_model.LinearRegression()\n",
    "max_lags=15\n",
    "r2_scores=np.zeros([max_lags-1])\n",
    "\n",
    "for n_lag in range(1,max_lags):\n",
    "    # Construct our new 'X' matrix\n",
    "    n_max=len(mortality_rates)\n",
    "    X=np.zeros([n_max-n_lag,n_lag])\n",
    "    for i in range(0,n_max-n_lag):\n",
    "        X[i]=mortality_rates[i:i+n_lag]\n",
    "    y=mortality_rates[n_lag:]\n",
    "    lin_reg.fit(X,y)\n",
    "    score=lin_reg.score(X,y)\n",
    "    r2_scores[n_lag-1]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(range(1,max_lags),r2_scores,'x-',lw=2,ms=10)\n",
    "plt.xlabel('# of lags')\n",
    "plt.ylabel('$R^2$ metric')\n",
    "plt.title('Training $R^2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do nonlinear models help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=neighbors.KNeighborsRegressor(n_neighbors=10)\n",
    "knn.fit(X,y)\n",
    "print('Explained R^2 on the training data is {}'.format(knn.score(X,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way higher! Does it hold up with cross-validation?\n",
    "We'll come back to this in a second.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about adding in the covariate information of interest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add the AQ measurements on the current day to predict the mortality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug=np.concatenate([X,covariates[n_lag:]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer=preprocessing.StandardScaler()\n",
    "knn=neighbors.KNeighborsRegressor(n_neighbors=10)\n",
    "pipe=pipeline.Pipeline([('norm',normalizer),('knn',knn)])\n",
    "pipe.fit(X_aug,y)\n",
    "print('Explained R^2 on the training data is {}'.format(pipe.score(X_aug,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we use our traditional cross-validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=metrics.mean_squared_error(lin_reg.predict(X),y)\n",
    "baseline_mse=metrics.mean_squared_error(np.mean(y).repeat(y.shape),y)\n",
    "print((baseline_mse-mse)/baseline_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't seem so bad, but will be very optimistic..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't worry about the lag distance at first, just different ways to split the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First approach, the wrong way :)\n",
    "Just randomize everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFold=model_selection.KFold(n_splits=4,random_state=10,shuffle=True)\n",
    "fig=plt.figure(figsize=[6,4])\n",
    "for train_ndx,valid_ndx in KFold.split(X,y):\n",
    "    plt.plot(y[valid_ndx],alpha=.5)\n",
    "plt.xlabel('Arbitrary Index')\n",
    "plt.ylabel('Morality Rate')\n",
    "plt.legend(['Split 1','Split 2','Split 3','Split 4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There still appears to be structure here, but this is due to the ordering of the split data points. Note that due to the correlation in the data our CV-estimates will be positively biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer=preprocessing.StandardScaler()\n",
    "knn=neighbors.KNeighborsRegressor(n_neighbors=10)\n",
    "pipe=pipeline.Pipeline([('norm',normalizer),('knn',knn)])\n",
    "explained_variance=np.mean(model_selection.cross_val_score(pipe,X_aug,y,scoring='explained_variance',cv=5))\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cross-validation, our performance estimate is significantly lower.  However, we still haven't gotten rid of correlation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about 'online' prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSS=model_selection.TimeSeriesSplit(n_splits=10)\n",
    "i=0\n",
    "for train_ndx,valid_ndx in TSS.split(X,y):\n",
    "    fig=plt.figure()\n",
    "    plt.plot(train_ndx,y[train_ndx],label='train')\n",
    "    plt.plot(valid_ndx,y[valid_ndx],label='valid')\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Mortality Rate')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    savepdf(fig,'ts_split_k_{}'.format(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSS=model_selection.TimeSeriesSplit(n_splits=10)\n",
    "scores=[]\n",
    "for train_ndx,valid_ndx in TSS.split(X,y):\n",
    "    valid_ndx_adjusted=valid_ndx\n",
    "    pipe.fit(X[train_ndx],y[train_ndx])\n",
    "    score=(metrics.mean_squared_error\\\n",
    "          (y[valid_ndx_adjusted],pipe.predict(X[valid_ndx_adjusted])))\n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "print('Average MSE of {0} with a standard error of {1}'.format(np.mean(scores),np.std(scores)/np.sqrt(KFold.n_splits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In same terms as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance=1-np.mean(scores)/metrics.mean_squared_error(np.mean(y).repeat(y.shape),y)\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a marked dropoff-- however, this is largely due to some of the early blocks where we didn't have as much data.  Considering dropping the first 2 blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(scores,'-x',ms=10,lw=2)\n",
    "plt.xlabel('Split Number')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance=1-np.mean(scores[2:])/metrics.mean_squared_error(np.mean(y).repeat(y.shape),y)\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives a _much_ better estimate of explained error. However, note that it is no longer comparing on the same dataset, so we must be careful in the analysis of these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments:\n",
    "I recomment the above method for the purposes of this class.  Below is for those that are interested in other options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation with pseudo-independent sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFold=model_selection.KFold(n_splits=4)\n",
    "for train_ndx,valid_ndx in KFold.split(X,y):\n",
    "    plt.plot(y[valid_ndx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because this is a 4-year dataset, the yearly structure pops out instantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize with trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimming=30\n",
    "KFold=model_selection.KFold(n_splits=10)\n",
    "i=0\n",
    "for train_ndx,valid_ndx in KFold.split(X,y):\n",
    "    fig=plt.figure()\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Mortality Rate')\n",
    "    trimmed=np.zeros(valid_ndx.shape,np.bool)\n",
    "    trimmed[:trimming]=True\n",
    "    trimmed[-trimming:]=True\n",
    "    plt.plot(train_ndx,y[train_ndx],'.',label='train')\n",
    "    plt.plot(valid_ndx[~trimmed],y[valid_ndx[~trimmed]],'.',label='valid')\n",
    "    plt.plot(valid_ndx[trimmed],y[valid_ndx[trimmed]],'.',label='trimmed')\n",
    "    plt.legend()\n",
    "    plt.show()  \n",
    "    savepdf(fig,'pis_split_k_{}'.format(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop some starting and ending datapoints to create a more independent testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFold=model_selection.KFold(n_splits=10)\n",
    "points_to_drop=10\n",
    "scores=[]\n",
    "for train_ndx,valid_ndx in KFold.split(X,y):\n",
    "    valid_ndx_adjusted=valid_ndx[points_to_drop:-points_to_drop]\n",
    "    pipe.fit(X[train_ndx],y[train_ndx])\n",
    "    score=(metrics.mean_squared_error\\\n",
    "          (y[valid_ndx_adjusted],pipe.predict(X[valid_ndx_adjusted])))\n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "print('Average MSE of {0} with a standard error of {1}'.format(np.mean(scores),np.std(scores)/np.sqrt(KFold.n_splits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance=1-np.mean(scores)/metrics.mean_squared_error(np.mean(y).repeat(y.shape),y)\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That got mildly worse, but not a major change.  Worst case can be pretty bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making an example where foreward prediction would give a drastically worse prediction than independent sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=150\n",
    "x_adv=np.random.randn(n)\n",
    "x_adv[75:]+=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFold=model_selection.KFold(n_splits=3,random_state=10,shuffle=False)\n",
    "fig=plt.figure()\n",
    "for train_ndx,valid_ndx in KFold.split(x_adv):\n",
    "    plt.plot(valid_ndx,x_adv[valid_ndx])\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Outcome, a.u.')\n",
    "plt.show()\n",
    "savepdf(fig,'adv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about this example.\n",
    "What would happen when you try to predict the 2nd group of points from just the first group?\n",
    "What would happen when you try to predict the 2nd group of points from the first and the third group of points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Autocorrelation Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's do this on the example that we've been working through above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "series = pd.Series(mortality_rates)\n",
    "fig=plt.figure()\n",
    "autocorrelation_plot(series)\n",
    "plt.show()\n",
    "savepdf(fig,'autocorr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at atmospheric CO2 concentrations.  In particular, there is a famous dataset from Mauna Loa: https://www.esrl.noaa.gov/gmd/ccgg/trends/full.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_df=pd.read_csv('./data/co2_weekly_mlo.txt',header=48,delim_whitespace=True)\n",
    "co2_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some quick_data_cleaning\n",
    "# replace missing numbers with NaNs for clarity\n",
    "missing=co2_df['ppm']<0\n",
    "co2_df['ppm'].values[missing]=np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times=co2_df['decimal']\n",
    "co2=co2_df['ppm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(times,co2)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('co2, ppm')\n",
    "plt.show()\n",
    "savepdf(fig,'c02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some missing data, so we'll do a quick interpolation.  We'll come back to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "not_observed=np.isnan(co2)\n",
    "interpolator=interp1d(times[~not_observed],co2[~not_observed],kind='cubic')\n",
    "co2_interpolated=interpolator(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(co2_interpolated)\n",
    "fig=plt.figure()\n",
    "autocorrelation_plot(series)\n",
    "plt.show()\n",
    "savepdf(fig,'autocorr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this isn't _clearly_ capturing the oscillatory trend.  Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the linear trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg=linear_model.LinearRegression()\n",
    "lin_reg.fit(times.values.reshape([-1,1]),co2_interpolated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_interpolated_residual=co2_interpolated-lin_reg.predict(times.values.reshape([-1,1]))\n",
    "fig=plt.figure()\n",
    "plt.plot(times,co2_interpolated_residual)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('co2 ppm, residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern now pops out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(co2_interpolated_residual)\n",
    "fig=plt.figure()\n",
    "autocorrelation_plot(series)\n",
    "plt.show()\n",
    "savepdf(fig,'autocorr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
